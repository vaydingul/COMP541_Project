{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Pkg; \n",
    "packages = [\"Knet\", \"AutoGrad\", \"Random\", \"Test\", \"MLDatasets\", \"CUDA\", \"Plots\", \"GR\",\"Statistics\",\n",
    "            \"IterTools\", \"StatsBase\", \"DSP\", \"Images\", \"DelimitedFiles\", \"MultivariateStats\", \"PyPlot\", \"PyCall\"];\n",
    "Pkg.add(packages);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../src/modules/TUM69.jl\")\n",
    "include(\"../src/modules/Preprocess.jl\")\n",
    "include(\"../src/modules/Network.jl\")\n",
    "include(\"../src/modules/Utils.jl\")\n",
    "\n",
    "## Third party packages\n",
    "using Knet: KnetArray, adam, relu, minibatch\n",
    "using CUDA: CuArray\n",
    "import CUDA\n",
    "using AutoGrad\n",
    "\n",
    "## Handwritten modules\n",
    "using .TUM69: load_accel_data   # Data reading\n",
    "using .Preprocess: process_accel_signal # Preprocessing on the data\n",
    "using .Network: GeneriCONV, train_summarize!, accuracy4 # Construction of custom network\n",
    "using .Utils: notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default_gc (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoGrad.set_gc_function(AutoGrad.default_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trick from Deniz Hoca to deal with this issue: https://github.com/denizyuret/Knet.jl/issues/524\n",
    "#=\n",
    "using Knet\n",
    "function Knet.KnetArray(x::CuArray{T,N}) where {T,N}\n",
    "    p = Base.bitcast(Knet.Cptr, pointer(x))\n",
    "    k = Knet.KnetPtr(p, sizeof(x), Int(CUDA.device().handle), x)\n",
    "    KnetArray{T,N}(k, size(x))\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a_type (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array type setting for GPU usage\n",
    "a_type() = (CUDA.functional() ? KnetArray{Float32} : Array{Float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDevice(0): Tesla T4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA information\n",
    "GC.gc(true)\n",
    "CUDA.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/userfiles/vaydingul20/data/new/\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/userfiles/vaydingul20/data/new/\" # path of the main data\n",
    "DATA_PATH = isdir(path) && path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accel data is being loaded!\n",
      "Test accel data is being loaded!\n",
      " 81.722035 seconds (732.60 M allocations: 24.039 GiB, 2.89% gc time)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train,\n",
    "X_test, y_test, \n",
    "material_dict = @time load_accel_data(DATA_PATH; mode = \"normal\");  # Data loading routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = 690-element Array{Array{Float32,1},1}\n",
      "y_train = 690-element Array{Int8,1}\n",
      "X_test  = 690-element Array{Array{Float32,1},1}\n",
      "y_test  = 690-element Array{Int8,1}\n",
      "material_dict = Dict{String,Int8} with 69 entries\n"
     ]
    }
   ],
   "source": [
    "println(\"X_train = \", summary(X_train))\n",
    "println(\"y_train = \", summary(y_train))\n",
    "println(\"X_test  = \", summary(X_test))\n",
    "println(\"y_test  = \", summary(y_test))\n",
    "println(\"material_dict = \", summary(material_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13.172702 seconds (6.89 M allocations: 6.301 GiB, 3.38% gc time)\n",
      "  7.362199 seconds (310.55 k allocations: 3.894 GiB, 4.93% gc time)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing on the acceleration data\n",
    "@time X_train_modified, y_train_modified = process_accel_signal(X_train, y_train);\n",
    "@time X_test_modified, y_test_modified = process_accel_signal(X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = 50×300×1×4489 Array{Float32,4}\n",
      "y_train = 4489-element Array{Int8,1}\n",
      "X_test  = 50×300×1×2223 Array{Float32,4}\n",
      "y_test  = 2223-element Array{Int8,1}\n",
      "material_dict = Dict{String,Int8} with 69 entries\n"
     ]
    }
   ],
   "source": [
    "println(\"X_train = \", summary(X_train_modified))\n",
    "println(\"y_train = \", summary(y_train_modified))\n",
    "println(\"X_test  = \", summary(X_test_modified))\n",
    "println(\"y_test  = \", summary(y_test_modified))\n",
    "println(\"material_dict = \", summary(material_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants that will be used in the network model\n",
    "MINIBATCH_SIZE = 10\n",
    "INPUT_SIZE = size(X_test_modified)[1:3]\n",
    "OUTPUT_SIZE = size(collect(keys(material_dict)))[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatching\n",
    "dtrn = minibatch(X_train_modified, y_train_modified, MINIBATCH_SIZE; xtype = a_type())\n",
    "dtst = minibatch(X_test_modified, y_test_modified, MINIBATCH_SIZE; xtype = a_type());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic model construction routine\n",
    "hn = GeneriCONV(INPUT_SIZE, 0.0, [(3, 3, 50, true), (3, 3, 100, true), (3, 3, 150, true),\n",
    "            (3, 3, 200, true), (3, 12, 400, false), (1, 1, 250, false), (1, 1, OUTPUT_SIZE, false)];\n",
    "            hidden = [], f = relu, a_type = a_type(), pdrop = 0.5, \n",
    "            optimizer_type = adam, lr = 1e-4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣██████████████▊     ┫ [74.00%, 33153/44800, 28:49/38:57, 1.39i/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdelete!\u001b[22m at \u001b[1m./dict.jl:645\u001b[22m [inlined]\n",
      " [2] \u001b[1mdelete!\u001b[22m at \u001b[1m./set.jl:66\u001b[22m [inlined]\n",
      " [3] \u001b[1mmacro expansion\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/CUDA/YeS8q/src/pool/binned.jl:103\u001b[22m [inlined]\n",
      " [4] \u001b[1mmacro expansion\u001b[22m at \u001b[1m./lock.jl:183\u001b[22m [inlined]\n",
      " [5] \u001b[1mpool_repopulate\u001b[22m\u001b[1m(\u001b[22m::CUDA.CuDevice\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/CUDA/YeS8q/src/pool/binned.jl:95\u001b[22m\n",
      " [6] \u001b[1mmacro expansion\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/CUDA/YeS8q/src/pool/binned.jl:153\u001b[22m [inlined]\n",
      " [7] \u001b[1mmacro expansion\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/TimerOutputs/ZmKD7/src/TimerOutput.jl:206\u001b[22m [inlined]\n",
      " [8] \u001b[1mpool_alloc\u001b[22m\u001b[1m(\u001b[22m::CUDA.CuDevice, ::Int64\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/CUDA/YeS8q/src/pool/binned.jl:152\u001b[22m\n",
      " [9] \u001b[1mmacro expansion\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/TimerOutputs/ZmKD7/src/TimerOutput.jl:206\u001b[22m [inlined]\n",
      " [10] \u001b[1mmacro expansion\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/CUDA/YeS8q/src/pool.jl:296\u001b[22m [inlined]\n",
      " [11] \u001b[1mmacro expansion\u001b[22m at \u001b[1m./timing.jl:233\u001b[22m [inlined]\n",
      " [12] \u001b[1malloc\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/CUDA/YeS8q/src/pool.jl:295\u001b[22m [inlined]\n",
      " [13] \u001b[1mCuArray{UInt8,1}\u001b[22m\u001b[1m(\u001b[22m::UndefInitializer, ::Tuple{Int64}\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/CUDA/YeS8q/src/array.jl:20\u001b[22m\n",
      " [14] \u001b[1mCuArray\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/CUDA/YeS8q/src/array.jl:76\u001b[22m [inlined]\n",
      " [15] \u001b[1mCuArray\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/CUDA/YeS8q/src/array.jl:77\u001b[22m [inlined]\n",
      " [16] \u001b[1mKnetPtrCu\u001b[22m\u001b[1m(\u001b[22m::Int64\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/knetarrays/kptr.jl:229\u001b[22m\n",
      " [17] \u001b[1mKnet.KnetArrays.KnetPtr\u001b[22m\u001b[1m(\u001b[22m::Int64\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/knetarrays/kptr.jl:107\u001b[22m\n",
      " [18] \u001b[1mKnetArray\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/knetarrays/karray.jl:75\u001b[22m [inlined]\n",
      " [19] \u001b[1msimilar\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/knetarrays/abstractarray.jl:28\u001b[22m [inlined]\n",
      " [20] \u001b[1msimilar\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/knetarrays/abstractarray.jl:26\u001b[22m [inlined]\n",
      " [21] \u001b[1mcudnnWorkSpace\u001b[22m\u001b[1m(\u001b[22m::KnetArray{Float32,4}, ::UInt64\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/ops20_gpu/conv.jl:254\u001b[22m\n",
      " [22] \u001b[1mconv4_algo\u001b[22m\u001b[1m(\u001b[22m::KnetArray{Float32,4}, ::KnetArray{Float32,4}, ::KnetArray{Float32,4}; handle::Ptr{Nothing}, o::Base.Iterators.Pairs{Symbol,Tuple{Int64,Int64},Tuple{Symbol},NamedTuple{(:padding,),Tuple{Tuple{Int64,Int64}}}}\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/ops20_gpu/conv.jl:179\u001b[22m\n",
      " [23] \u001b[1mconv4\u001b[22m\u001b[1m(\u001b[22m::KnetArray{Float32,4}, ::KnetArray{Float32,4}; handle::Ptr{Nothing}, alpha::Int64, o::Base.Iterators.Pairs{Symbol,Tuple{Int64,Int64},Tuple{Symbol},NamedTuple{(:padding,),Tuple{Tuple{Int64,Int64}}}}\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/ops20_gpu/conv.jl:9\u001b[22m\n",
      " [24] \u001b[1mforw\u001b[22m\u001b[1m(\u001b[22m::Function, ::Param{KnetArray{Float32,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Symbol,Tuple{Int64,Int64},Tuple{Symbol},NamedTuple{(:padding,),Tuple{Tuple{Int64,Int64}}}}\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/AutoGrad/VFrAv/src/core.jl:66\u001b[22m\n",
      " [25] \u001b[1m#conv4#22\u001b[22m at \u001b[1m./none:0\u001b[22m [inlined]\n",
      " [26] \u001b[1m(::Main.Network.Conv)\u001b[22m\u001b[1m(\u001b[22m::AutoGrad.Result{KnetArray{Float32,4}}\u001b[1m)\u001b[22m at \u001b[1m/scratch/users/vaydingul20/workfolder/COMP541_Project/src/modules/Network.jl:110\u001b[22m\n",
      " [27] \u001b[1m(::GeneriCONV)\u001b[22m\u001b[1m(\u001b[22m::KnetArray{Float32,4}\u001b[1m)\u001b[22m at \u001b[1m/scratch/users/vaydingul20/workfolder/COMP541_Project/src/modules/Network.jl:187\u001b[22m\n",
      " [28] \u001b[1m(::GeneriCONV)\u001b[22m\u001b[1m(\u001b[22m::KnetArray{Float32,4}, ::Array{Int8,1}\u001b[1m)\u001b[22m at \u001b[1m/scratch/users/vaydingul20/workfolder/COMP541_Project/src/modules/Network.jl:197\u001b[22m\n",
      " [29] \u001b[1m(::Knet.Train20.var\"#27#28\"{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}},Tuple{KnetArray{Float32,4},Array{Int8,1}}})\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/AutoGrad/VFrAv/src/core.jl:205\u001b[22m\n",
      " [30] \u001b[1mdifferentiate\u001b[22m\u001b[1m(\u001b[22m::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/AutoGrad/VFrAv/src/core.jl:144\u001b[22m\n",
      " [31] \u001b[1mdifferentiate\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/AutoGrad/VFrAv/src/core.jl:135\u001b[22m [inlined]\n",
      " [32] \u001b[1miterate\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/train20/train.jl:26\u001b[22m [inlined]\n",
      " [33] \u001b[1miterate\u001b[22m\u001b[1m(\u001b[22m::Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}, ::Tuple{Int64,Int64}\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/train20/progress.jl:73\u001b[22m\n",
      " [34] \u001b[1miterate\u001b[22m\u001b[1m(\u001b[22m::IterTools.TakeNth{Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}}, ::Tuple{Int64,Int64}\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/IterTools/0dYLc/src/IterTools.jl:82\u001b[22m\n",
      " [35] \u001b[1miterate\u001b[22m at \u001b[1m./generator.jl:44\u001b[22m [inlined]\n",
      " [36] \u001b[1miterate\u001b[22m\u001b[1m(\u001b[22m::Base.Iterators.Flatten{Base.Generator{IterTools.TakeNth{Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}},Main.Network.var\"#22#24\"{GeneriCONV,Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}},Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}, ::Tuple{Tuple{Int64,Int64},Tuple{Float32,Float32,Float64,Float64},Int64}\u001b[1m)\u001b[22m at \u001b[1m./iterators.jl:1068\u001b[22m\n",
      " [37] \u001b[1m_collect\u001b[22m\u001b[1m(\u001b[22m::Type{Float32}, ::Base.Iterators.Flatten{Base.Generator{IterTools.TakeNth{Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}},Main.Network.var\"#22#24\"{GeneriCONV,Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}},Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}, ::Base.SizeUnknown\u001b[1m)\u001b[22m at \u001b[1m./array.jl:590\u001b[22m\n",
      " [38] \u001b[1mcollect\u001b[22m\u001b[1m(\u001b[22m::Type{Float32}, ::Base.Iterators.Flatten{Base.Generator{IterTools.TakeNth{Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}},Main.Network.var\"#22#24\"{GeneriCONV,Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}},Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}\u001b[1m)\u001b[22m at \u001b[1m./array.jl:583\u001b[22m\n",
      " [39] \u001b[1mtrain_summarize!\u001b[22m\u001b[1m(\u001b[22m::GeneriCONV, ::Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}, ::Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}; train_type::String, fig::Bool, info::Bool, epoch::Int64, conv_epoch::Int64, max_conv_cycle::Int64\u001b[1m)\u001b[22m at \u001b[1m/scratch/users/vaydingul20/workfolder/COMP541_Project/src/modules/Network.jl:353\u001b[22m\n",
      " [40] top-level scope at \u001b[1mIn[22]:4\u001b[22m\n",
      " [41] \u001b[1minclude_string\u001b[22m\u001b[1m(\u001b[22m::Function, ::Module, ::String, ::String\u001b[1m)\u001b[22m at \u001b[1m./loading.jl:1091\u001b[22m\n",
      " [42] \u001b[1msoftscope_include_string\u001b[22m\u001b[1m(\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/SoftGlobalScope/u4UzH/src/SoftGlobalScope.jl:65\u001b[22m\n",
      " [43] \u001b[1mexecute_request\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/IJulia/ljYVo/src/execute_request.jl:67\u001b[22m\n",
      " [44] \u001b[1m#invokelatest#1\u001b[22m at \u001b[1m./essentials.jl:710\u001b[22m [inlined]\n",
      " [45] \u001b[1minvokelatest\u001b[22m at \u001b[1m./essentials.jl:709\u001b[22m [inlined]\n",
      " [46] \u001b[1meventloop\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m at \u001b[1m/kuacc/users/vaydingul20/.julia/packages/IJulia/ljYVo/src/eventloop.jl:8\u001b[22m\n",
      " [47] \u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m./task.jl:356\u001b[22m\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /kuacc/users/vaydingul20/.julia/packages/AutoGrad/VFrAv/src/core.jl:148",
      " [2] differentiate at /kuacc/users/vaydingul20/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]",
      " [3] iterate at /kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/train20/train.jl:26 [inlined]",
      " [4] iterate(::Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}, ::Tuple{Int64,Int64}) at /kuacc/users/vaydingul20/.julia/packages/Knet/LdQyF/src/train20/progress.jl:73",
      " [5] iterate(::IterTools.TakeNth{Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}}, ::Tuple{Int64,Int64}) at /kuacc/users/vaydingul20/.julia/packages/IterTools/0dYLc/src/IterTools.jl:82",
      " [6] iterate at ./generator.jl:44 [inlined]",
      " [7] iterate(::Base.Iterators.Flatten{Base.Generator{IterTools.TakeNth{Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}},Main.Network.var\"#22#24\"{GeneriCONV,Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}},Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}, ::Tuple{Tuple{Int64,Int64},Tuple{Float32,Float32,Float64,Float64},Int64}) at ./iterators.jl:1068",
      " [8] _collect(::Type{Float32}, ::Base.Iterators.Flatten{Base.Generator{IterTools.TakeNth{Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}},Main.Network.var\"#22#24\"{GeneriCONV,Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}},Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}, ::Base.SizeUnknown) at ./array.jl:590",
      " [9] collect(::Type{Float32}, ::Base.Iterators.Flatten{Base.Generator{IterTools.TakeNth{Knet.Train20.Progress{Knet.Train20.Minimize{IterTools.NCycle{Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}},Main.Network.var\"#22#24\"{GeneriCONV,Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}},Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}}}}) at ./array.jl:583",
      " [10] train_summarize!(::GeneriCONV, ::Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}, ::Knet.Train20.Data{Tuple{KnetArray{Float32,N} where N,Array{Int8,N} where N}}; train_type::String, fig::Bool, info::Bool, epoch::Int64, conv_epoch::Int64, max_conv_cycle::Int64) at /scratch/users/vaydingul20/workfolder/COMP541_Project/src/modules/Network.jl:353",
      " [11] top-level scope at In[22]:4",
      " [12] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "# Training routine\n",
    "# Currently, the model is not working due to the issue mentioned in: https://github.com/denizyuret/Knet.jl/issues/624#\n",
    "# As soon as it is solved, I hope the model will be accurately working.\n",
    "res = train_summarize!(hn, dtrn, dtst; \n",
    "                       train_type = \"epoch\", fig = true, info = true, \n",
    "                       epoch = 100, conv_epoch = 50, max_conv_cycle = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100     7  100     2  100     5      1      4  0:00:02  0:00:01  0:00:01     6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mcurl\u001b[24m \u001b[4mhttps://notify.run/fnx04zT7QmOlLLa6\u001b[24m \u001b[4m-d\u001b[24m \u001b[4mDONE!\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notify(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
