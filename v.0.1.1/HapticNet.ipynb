{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=\n",
    "using Pkg; \n",
    "packages = [\"Knet\", \"AutoGrad\", \"Random\", \"Test\", \"MLDatasets\", \"CUDA\", \"Plots\", \"GR\",\"Statistics\",\n",
    "            \"IterTools\", \"StatsBase\", \"DSP\", \"Images\", \"DelimitedFiles\", \"MultivariateStats\", \"PyPlot\", \"PyCall\"];\n",
    "Pkg.add(packages);\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: syntax: missing comma or ) in argument list\nin expression starting at /scratch/users/vaydingul20/workfolder/COMP541_Project/src/modules/Network.jl:251",
     "output_type": "error",
     "traceback": [
      "LoadError: syntax: missing comma or ) in argument list\nin expression starting at /scratch/users/vaydingul20/workfolder/COMP541_Project/src/modules/Network.jl:251",
      "",
      "Stacktrace:",
      " [1] top-level scope at /scratch/users/vaydingul20/workfolder/COMP541_Project/src/modules/Network.jl:251",
      " [2] include(::String) at ./client.jl:457",
      " [3] top-level scope at In[1]:3",
      " [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "include(\"../src/modules/TUM69.jl\")\n",
    "include(\"../src/modules/Preprocess.jl\")\n",
    "include(\"../src/modules/Network.jl\")\n",
    "include(\"../src/modules/Utils.jl\")\n",
    "\n",
    "## Third party packages\n",
    "using Knet: KnetArray, adam, relu, minibatch\n",
    "using AutoGrad, Knet, CUDA\n",
    "\n",
    "\n",
    "## Handwritten modules\n",
    "using .TUM69: load_accel_data   # Data reading\n",
    "using .Preprocess: process_accel_signal # Preprocessing on the data\n",
    "using .Network: GCN, train_summarize!, accuracy4, nll4, GenericMLP # Construction of custom network\n",
    "using .Utils: notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: AutoGrad not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: AutoGrad not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[2]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "AutoGrad.set_gc_function(AutoGrad.default_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trick from Deniz Hoca to deal with this issue: https://github.com/denizyuret/Knet.jl/issues/524\n",
    "#=\n",
    "using Knet\n",
    "function Knet.KnetArray(x::CuArray{T,N}) where {T,N}\n",
    "    p = Base.bitcast(Knet.Cptr, pointer(x))\n",
    "    k = Knet.KnetPtr(p, sizeof(x), Int(CUDA.device().handle), x)\n",
    "    KnetArray{T,N}(k, size(x))\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a_type (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array type setting for GPU usage\n",
    "a_type() = (CUDA.functional() ? KnetArray{Float32} : Array{Float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: CUDA not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: CUDA not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[5]:3",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "# CUDA information\n",
    "GC.gc(true)\n",
    "CUDA.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: CUDA not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: CUDA not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[6]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "path = CUDA.functional() ? \"/userfiles/vaydingul20/data/trial\" : \"./../data/trial\" # path of the main data\n",
    "DATA_PATH = isdir(path) && path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: load_accel_data not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: load_accel_data not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at ./timing.jl:174 [inlined]",
      " [2] top-level scope at ./In[7]:0",
      " [3] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "X_train, y_train,\n",
    "X_test, y_test, \n",
    "material_dict = @time load_accel_data(DATA_PATH; mode = \"baseline\");  # Data loading routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X_train not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X_train not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[8]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "println(\"X_train = \", summary(X_train))\n",
    "println(\"y_train = \", summary(y_train))\n",
    "println(\"X_test  = \", summary(X_test))\n",
    "println(\"y_test  = \", summary(y_test))\n",
    "println(\"material_dict = \", summary(material_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: process_accel_signal not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: process_accel_signal not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at ./timing.jl:174 [inlined]",
      " [2] top-level scope at ./In[9]:0",
      " [3] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "#Preprocessing on the acceleration data\n",
    "@time X_train_modified, y_train_modified = process_accel_signal(X_train, y_train);\n",
    "@time X_test_modified, y_test_modified = process_accel_signal(X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X_train_modified not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X_train_modified not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[10]:2",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "using Plots\n",
    "heatmap(X_train_modified[:,:,1,4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X_train_modified not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X_train_modified not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[11]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "println(\"X_train = \", summary(X_train_modified))\n",
    "println(\"y_train = \", summary(y_train_modified))\n",
    "println(\"X_test  = \", summary(X_test_modified))\n",
    "println(\"y_test  = \", summary(y_test_modified))\n",
    "println(\"material_dict = \", summary(material_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X_test_modified not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X_test_modified not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[12]:3",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "# Some constants that will be used in the network model\n",
    "MINIBATCH_SIZE = 10\n",
    "INPUT_SIZE = size(X_test_modified)[1:3]\n",
    "OUTPUT_SIZE = size(collect(keys(material_dict)))[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: CUDA not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: CUDA not defined",
      "",
      "Stacktrace:",
      " [1] a_type() at ./In[4]:2",
      " [2] top-level scope at In[13]:2",
      " [3] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "# Minibatching\n",
    "dtrn = minibatch(X_train_modified, y_train_modified, MINIBATCH_SIZE; xtype = a_type(), shuffle = true)\n",
    "dtst = minibatch(X_test_modified, y_test_modified, MINIBATCH_SIZE; xtype = a_type(), shuffle = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "model = GCN(INPUT_SIZE, OUTPUT_SIZE, \n",
    "       [(25, 150, 1 , relu, 0.0, (1, 1), (1, 1), (2, 2), false)]; \n",
    "    hidden=[10], optimizer_type = sgd, lr = 0.15, loss_fnc=nll, accuracy_fnc = accuracy, atype=a_type())\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: relu not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: relu not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[15]:2",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "\n",
    "model = GCN(INPUT_SIZE, OUTPUT_SIZE, \n",
    "       [(3, 3, 50 , relu, 0.0, (1, 1), (1, 1), (2, 2), true),\n",
    "        (3, 3, 100, relu, 0.0, (1, 1), (1, 1), (2, 2), false),\n",
    "        (3, 3, 150, relu, 0.0, (1, 1), (1, 1), (2, 2), false),\n",
    "        (3, 3, 200, relu, 0.0, (1, 1), (1, 1), (2, 2), false),\n",
    "        (4, 12,400, relu, 0.5, (1, 0), (1, 1), (1, 1), false),\n",
    "        (1, 1, 250, relu, 0.5, (0, 0), (1, 1), (1, 1), false),\n",
    "        (1, 1, OUTPUT_SIZE , relu, 0.5, (0, 0), (1, 1), (1, 1), false),\n",
    "        ]; \n",
    "    hidden=[], optimizer_type = adam, lr = 1e-4, loss_fnc=nll4, accuracy_fnc = accuracy4, atype=a_type())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: model not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[16]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "model(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: train_summarize! not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: train_summarize! not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[17]:4",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "# Training routine\n",
    "# Currently, the model is not working due to the issue mentioned in: https://github.com/denizyuret/Knet.jl/issues/624#\n",
    "# As soon as it is solved, I hope the model will be accurately working.\n",
    "res = train_summarize!(model, dtrn, dtst; \n",
    "                       train_type = \"epoch\", progress_bar = true ,fig = true, info = true, \n",
    "                       epoch = 100, conv_epoch = 50, max_conv_cycle = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100     3    0     0  100     3      0      2  0:00:01  0:00:01 --:--:--     2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100     5  100     2  100     3      1      1  0:00:03  0:00:01  0:00:02     2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mcurl\u001b[24m \u001b[4mhttps://notify.run/fnx04zT7QmOlLLa6\u001b[24m \u001b[4m-d\u001b[24m \u001b[4mOK!\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notify(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
