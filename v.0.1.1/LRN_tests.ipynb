{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../src/modules/TUM69.jl\")\n",
    "include(\"../src/modules/Preprocess.jl\")\n",
    "include(\"../src/modules/Network.jl\")\n",
    "include(\"../src/modules/Utils.jl\")\n",
    "\n",
    "## Third party packages\n",
    "using Knet: KnetArray, adam, relu, minibatch\n",
    "using AutoGrad, Knet, CUDA\n",
    "\n",
    "\n",
    "## Handwritten modules\n",
    "using .TUM69: load_accel_data   # Data reading\n",
    "using .Preprocess: process_accel_signal # Preprocessing on the data\n",
    "using .Network: GCN, train_summarize!, accuracy4, nll4, GenericMLP # Construction of custom network\n",
    "using .Utils: notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__LR_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function LR_norm(x; atype = Array{Float32}, o...)\n",
    "    _, _, _, batch_size = size(x)\n",
    "         \n",
    "    x_ = []\n",
    "            for k in 1:batch_size\n",
    "                \n",
    "               push!(x_, _LR_norm(x[: ,:, :, k]; atype = atype, o...))\n",
    "   \n",
    "            end\n",
    "\n",
    "     x = cat(x_...; dims = 4)\n",
    "        return x\n",
    "     end\n",
    "\n",
    "    function _LR_norm(x; atype =  Array{Float32}, o...)\n",
    "    \n",
    "        nx, ny, nc = size(x)\n",
    "        \n",
    "        x = mat(x; dims = 2)\n",
    "        x_ = []#Array{atype}(undef, 0)\n",
    "        for k = 1:(nx * ny)\n",
    "            \n",
    "        push!(x_, __LR_norm(x[k, :]; atype = atype, o...))\n",
    "        \n",
    "        end\n",
    "    x_ = cat(x_...; dims = 2)\n",
    "    x = reshape(x_', (nx, ny, nc))\n",
    "    return x\n",
    "        \n",
    "    end\n",
    "\n",
    "    function __LR_norm(x; atype =  Array{Float32}, k = 2, n = 5, alpha = 0.0001, beta = 0.75)\n",
    "        nc = size(x, 1)\n",
    "        x_ = [] #atype(undef, 0)\n",
    "        for i in 1:nc\n",
    "            _lower = convert(Int, floor(max(1., i - n/2)))\n",
    "            _upper = convert(Int, floor(min(nc, i + n/2)))\n",
    "            _sum = sum(x[_lower:_upper].^2)\n",
    "            push!(x_, x[i] ./ ((k .+ alpha .* _sum).^beta))\n",
    "        \n",
    "        end\n",
    "        x = x_\n",
    "        return x\n",
    "    end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3×4×1 Array{Any,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.5      0.25      0.3\n",
       " 0.2      0.166667  0.15\n",
       " 0.12069  0.1       0.1\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.166667   0.222222   0.0714286\n",
       " 0.0689655  0.136364   0.0408163\n",
       " 0.0405405  0.0449438  0.0283019\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0952381  0.111111  0.333333\n",
       " 0.0789474  0.117647  0.214286\n",
       " 0.137931   0.103448  0.097561\n",
       "\n",
       "[:, :, 4, 1] =\n",
       " 0.2       0.4       0.2\n",
       " 0.147059  0.25      0.1\n",
       " 0.1       0.153846  0.125"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(3,3,4,1))\n",
    "x = Param(x)\n",
    "x[:, :, 1, 1] = [1  2  3; 4  3  6; 7  8  9]\n",
    "x[:, :, 2, 1] = [1  2  1; 2  3  2; 3  4  3]\n",
    "x[:, :, 3, 1] = [2  1  2; 3  2  3; 4  3  4]\n",
    "x[:, :, 4, 1] = [4  2  1; 5  2  1; 2  2  4]\n",
    "y = LR_norm(x; k = 0, n = 2, alpha = 1, beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sparse(Array{Float32,4}(2,2,2,2)(2, 2, 2)(2, 2, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(2,2,2,2))\n",
    "x = Param(x)\n",
    "J = @diff sum(abs2, LR_norm(x))\n",
    "grad(J, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_LR_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function LR_norm(x; atype = Array, o...)\n",
    "    \n",
    "        _, _, _, batch_size = size(x)\n",
    "        @show typeof(x)\n",
    "        #if atype <: Array\n",
    "            for k in 1:batch_size\n",
    "                \n",
    "                x[:, :, :, k] = mapslices(x -> _LR_norm(x; o...), (x[:, :, :, k]), dims = 3)\n",
    "                \n",
    "            end\n",
    "       #= else\n",
    "            for k in 1:batch_size\n",
    "                \n",
    "                x[:, :, :, k] = atype(mapslices(x -> _LR_norm(x; o...), Array(x[:, :, :, k]), dims = 3))\n",
    "                \n",
    "            end\n",
    "        end\n",
    "=#\n",
    "        return x\n",
    "     end\n",
    "\n",
    "\n",
    "\n",
    "    function _LR_norm(x; k = 2, n = 5, alpha = 0.0001, beta = 0.75, atype = Array)\n",
    "    \n",
    "        nc = length(x)\n",
    "        x_ = zeros(nc)\n",
    "        #x_ = atype(zeros(nc))\n",
    "        for i in 1:nc\n",
    "            \n",
    "            _lower = convert(Int, floor(max(1., i - n/2)))\n",
    "            _upper = convert(Int, floor(min(nc, i + n/2)))\n",
    "            _sum = sum(x[_lower:_upper].^2)\n",
    "            x_[i] = x[i] ./ ((k .+ alpha .* _sum).^beta)\n",
    "        end\n",
    "        \n",
    "        return x_\n",
    "    end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(x) = Param{Array{Float32,4}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3×4×1 Param{Array{Float32,4}}:\n",
       "[:, :, 1, 1] =\n",
       " 0.5      0.25      0.3\n",
       " 0.2      0.166667  0.15\n",
       " 0.12069  0.1       0.1\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.166667   0.222222   0.0714286\n",
       " 0.0689655  0.136364   0.0408163\n",
       " 0.0405405  0.0449438  0.0283019\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0952381  0.111111  0.333333\n",
       " 0.0789474  0.117647  0.214286\n",
       " 0.137931   0.103448  0.097561\n",
       "\n",
       "[:, :, 4, 1] =\n",
       " 0.2       0.4       0.2\n",
       " 0.147059  0.25      0.1\n",
       " 0.1       0.153846  0.125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(3,3,4,1))\n",
    "x = Param(x)\n",
    "x[:, :, 1, 1] = [1  2  3; 4  3  6; 7  8  9]\n",
    "x[:, :, 2, 1] = [1  2  1; 2  3  2; 3  4  3]\n",
    "x[:, :, 3, 1] = [2  1  2; 3  2  3; 4  3  4]\n",
    "x[:, :, 4, 1] = [4  2  1; 5  2  1; 2  2  4]\n",
    "y = LR_norm(x; k = 0, n = 2, alpha = 1, beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(x) = Param{Array{Float32,4}}\n",
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[1mLR_norm\u001b[22m\u001b[1m(\u001b[22m::Param{Array{Float32,4}}; atype::Type{T} where T, o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}\u001b[1m)\u001b[22m at \u001b[1m.\\In[5]:9\u001b[22m\n",
      " [2] \u001b[1mLR_norm\u001b[22m\u001b[1m(\u001b[22m::Param{Array{Float32,4}}\u001b[1m)\u001b[22m at \u001b[1m.\\In[5]:4\u001b[22m\n",
      " [3] \u001b[1m(::var\"#10#11\")\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:205\u001b[22m\n",
      " [4] \u001b[1mdifferentiate\u001b[22m\u001b[1m(\u001b[22m::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:144\u001b[22m\n",
      " [5] \u001b[1mdifferentiate\u001b[22m\u001b[1m(\u001b[22m::Function\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:135\u001b[22m\n",
      " [6] top-level scope at \u001b[1mIn[7]:3\u001b[22m\n",
      " [7] \u001b[1minclude_string\u001b[22m\u001b[1m(\u001b[22m::Function, ::Module, ::String, ::String\u001b[1m)\u001b[22m at \u001b[1m.\\loading.jl:1091\u001b[22m\n",
      " [8] \u001b[1msoftscope_include_string\u001b[22m\u001b[1m(\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\SoftGlobalScope\\u4UzH\\src\\SoftGlobalScope.jl:65\u001b[22m\n",
      " [9] \u001b[1mexecute_request\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\IJulia\\IDNmS\\src\\execute_request.jl:67\u001b[22m\n",
      " [10] \u001b[1m#invokelatest#1\u001b[22m at \u001b[1m.\\essentials.jl:710\u001b[22m [inlined]\n",
      " [11] \u001b[1minvokelatest\u001b[22m at \u001b[1m.\\essentials.jl:709\u001b[22m [inlined]\n",
      " [12] \u001b[1meventloop\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\IJulia\\IDNmS\\src\\eventloop.jl:8\u001b[22m\n",
      " [13] \u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m.\\task.jl:356\u001b[22m\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching mapslices(::var\"#7#8\"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}}, ::AutoGrad.Result{Array{Float32,3}}; dims=3)\nClosest candidates are:\n  mapslices(::Any, !Matched::AbstractArray; dims) at abstractarray.jl:2061",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching mapslices(::var\"#7#8\"{Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}}, ::AutoGrad.Result{Array{Float32,3}}; dims=3)\nClosest candidates are:\n  mapslices(::Any, !Matched::AbstractArray; dims) at abstractarray.jl:2061",
      "",
      "Stacktrace:",
      " [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:148",
      " [2] differentiate(::Function) at C:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:135",
      " [3] top-level scope at In[7]:3",
      " [4] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "x = Array{Float32}(randn(2,2,2,2))\n",
    "x = Param(x)\n",
    "J = @diff sum(abs2, LR_norm(x))\n",
    "grad(J, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_LR_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function LR_norm_ground(x; atype = Array, o...)\n",
    "    \n",
    "        nx, ny, _, batch_size = size(x)\n",
    "            for k in 1:batch_size\n",
    "                for m in 1:nx\n",
    "                for n in 1:ny\n",
    "                \n",
    "                x[m, n, :, k] = _LR_norm(x[m, n, :, k]; o...)\n",
    "            end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "    return x\n",
    "end\n",
    "\n",
    "    function _LR_norm(x; k = 2, n = 5, alpha = 0.0001, beta = 0.75, atype = Array)\n",
    "        nc = length(x)\n",
    "        x_ = zeros(nc)\n",
    "        #x_ = atype(zeros(nc))\n",
    "        for i in 1:nc\n",
    "            \n",
    "            _lower = convert(Int, floor(max(1., i - n/2)))\n",
    "            _upper = convert(Int, floor(min(nc, i + n/2)))\n",
    "            _sum = sum(x[_lower:_upper].^2)\n",
    "            x_[i] = x[i] ./ ((k .+ alpha .* _sum).^beta)\n",
    "        end\n",
    "        x = x_\n",
    "        return x\n",
    "    end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3×4×1 Param{Array{Float32,4}}:\n",
       "[:, :, 1, 1] =\n",
       " 0.5      0.25      0.3\n",
       " 0.2      0.166667  0.15\n",
       " 0.12069  0.1       0.1\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.166667   0.222222   0.0714286\n",
       " 0.0689655  0.136364   0.0408163\n",
       " 0.0405405  0.0449438  0.0283019\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0952381  0.111111  0.333333\n",
       " 0.0789474  0.117647  0.214286\n",
       " 0.137931   0.103448  0.097561\n",
       "\n",
       "[:, :, 4, 1] =\n",
       " 0.2       0.4       0.2\n",
       " 0.147059  0.25      0.1\n",
       " 0.1       0.153846  0.125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(3,3,4,1))\n",
    "x = Param(x)\n",
    "x[:, :, 1, 1] = [1  2  3; 4  3  6; 7  8  9]\n",
    "x[:, :, 2, 1] = [1  2  1; 2  3  2; 3  4  3]\n",
    "x[:, :, 3, 1] = [2  1  2; 3  2  3; 4  3  4]\n",
    "x[:, :, 4, 1] = [4  2  1; 5  2  1; 2  2  4]\n",
    "y = LR_norm(x; k = 0, n = 2, alpha = 1, beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[1msetindex!\u001b[22m\u001b[1m(\u001b[22m::Array{Float64,1}, ::AutoGrad.Result{Float64}, ::Int64\u001b[1m)\u001b[22m at \u001b[1m.\\array.jl:847\u001b[22m\n",
      " [2] \u001b[1m_LR_norm\u001b[22m\u001b[1m(\u001b[22m::AutoGrad.Result{Array{Float32,1}}; k::Int64, n::Int64, alpha::Float64, beta::Float64, atype::Type{T} where T\u001b[1m)\u001b[22m at \u001b[1m.\\In[8]:26\u001b[22m\n",
      " [3] \u001b[1m_LR_norm\u001b[22m\u001b[1m(\u001b[22m::AutoGrad.Result{Array{Float32,1}}\u001b[1m)\u001b[22m at \u001b[1m.\\In[8]:18\u001b[22m\n",
      " [4] \u001b[1mLR_norm\u001b[22m\u001b[1m(\u001b[22m::Param{Array{Float32,4}}; atype::Type{T} where T, o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}\u001b[1m)\u001b[22m at \u001b[1m.\\In[8]:9\u001b[22m\n",
      " [5] \u001b[1mLR_norm\u001b[22m\u001b[1m(\u001b[22m::Param{Array{Float32,4}}\u001b[1m)\u001b[22m at \u001b[1m.\\In[8]:4\u001b[22m\n",
      " [6] \u001b[1m(::var\"#14#15\")\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:205\u001b[22m\n",
      " [7] \u001b[1mdifferentiate\u001b[22m\u001b[1m(\u001b[22m::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:144\u001b[22m\n",
      " [8] \u001b[1mdifferentiate\u001b[22m\u001b[1m(\u001b[22m::Function\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:135\u001b[22m\n",
      " [9] top-level scope at \u001b[1mIn[10]:3\u001b[22m\n",
      " [10] \u001b[1minclude_string\u001b[22m\u001b[1m(\u001b[22m::Function, ::Module, ::String, ::String\u001b[1m)\u001b[22m at \u001b[1m.\\loading.jl:1091\u001b[22m\n",
      " [11] \u001b[1msoftscope_include_string\u001b[22m\u001b[1m(\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\SoftGlobalScope\\u4UzH\\src\\SoftGlobalScope.jl:65\u001b[22m\n",
      " [12] \u001b[1mexecute_request\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\IJulia\\IDNmS\\src\\execute_request.jl:67\u001b[22m\n",
      " [13] \u001b[1m#invokelatest#1\u001b[22m at \u001b[1m.\\essentials.jl:710\u001b[22m [inlined]\n",
      " [14] \u001b[1minvokelatest\u001b[22m at \u001b[1m.\\essentials.jl:709\u001b[22m [inlined]\n",
      " [15] \u001b[1meventloop\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m at \u001b[1mC:\\Users\\volkan\\.julia\\packages\\IJulia\\IDNmS\\src\\eventloop.jl:8\u001b[22m\n",
      " [16] \u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m.\\task.jl:356\u001b[22m\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: Cannot `convert` an object of type AutoGrad.Result{Float64} to an object of type Float64\nClosest candidates are:\n  convert(::Type{T}, !Matched::Ratios.SimpleRatio{S}) where {T<:AbstractFloat, S} at C:\\Users\\volkan\\.julia\\packages\\Ratios\\uRs4y\\src\\Ratios.jl:13\n  convert(::Type{T}, !Matched::T) where T<:Number at number.jl:6\n  convert(::Type{T}, !Matched::Number) where T<:Number at number.jl:7\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: Cannot `convert` an object of type AutoGrad.Result{Float64} to an object of type Float64\nClosest candidates are:\n  convert(::Type{T}, !Matched::Ratios.SimpleRatio{S}) where {T<:AbstractFloat, S} at C:\\Users\\volkan\\.julia\\packages\\Ratios\\uRs4y\\src\\Ratios.jl:13\n  convert(::Type{T}, !Matched::T) where T<:Number at number.jl:6\n  convert(::Type{T}, !Matched::Number) where T<:Number at number.jl:7\n  ...",
      "",
      "Stacktrace:",
      " [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:148",
      " [2] differentiate(::Function) at C:\\Users\\volkan\\.julia\\packages\\AutoGrad\\VFrAv\\src\\core.jl:135",
      " [3] top-level scope at In[10]:3",
      " [4] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "x = Array{Float32}(randn(2,2,2,2))\n",
    "x = Param(x)\n",
    "J = @diff sum(abs2, LR_norm(x))\n",
    "grad(J, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_LR_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function LR_norm(x::T; o...) where T\n",
    "    \n",
    "        nx, ny, nc, batch_size = size(x)\n",
    "        \n",
    "        x = mat(permutedims(x, (3,1,2,4)); dims = 1)\n",
    "\n",
    "        x = x'\n",
    "        \n",
    "        y = similar(x)\n",
    "    \n",
    "        x = getindex.([x], 1:size(x, 1), :)\n",
    "        @show x\n",
    "        @show size(x)\n",
    "        y = _LR_norm.(x; o...)\n",
    "\n",
    "        y = vcat(y'...)\n",
    "\n",
    "        y = reshape(y, (nx, ny, batch_size, nc))\n",
    "\n",
    "        y = permutedims(y, (1,2,4,3))\n",
    "\n",
    "    return y\n",
    "end\n",
    "\n",
    "    function _LR_norm(x::T; k = 2, n = 5, alpha = 0.0001, beta = 0.75) where T\n",
    " \n",
    "    #@show size(x)\n",
    "    k, n, alpha, beta = convert.(eltype(T), [k, n, alpha, beta]) \n",
    "    \n",
    "    nc = length(x)\n",
    "    \n",
    "    _sum = []\n",
    "    \n",
    "        for i in 1:nc\n",
    "            \n",
    "            _lower = convert(Int, floor(max(1., i - n/2)))\n",
    "            _upper = convert(Int, floor(min(nc, i + n/2)))\n",
    "            push!(_sum,  sum(x[_lower:_upper].^2))\n",
    "            \n",
    "        end\n",
    "    _sum = vcat(_sum...)\n",
    "        return x./((k .+ alpha .* _sum).^beta)\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Array{Float32,1}[[1.0, 1.0, 2.0, 4.0], [4.0, 2.0, 3.0, 5.0], [7.0, 3.0, 4.0, 2.0], [2.0, 2.0, 1.0, 2.0], [3.0, 3.0, 2.0, 2.0], [8.0, 4.0, 3.0, 2.0], [3.0, 1.0, 2.0, 1.0], [6.0, 2.0, 3.0, 1.0], [9.0, 3.0, 4.0, 4.0]]\n",
      "size(x) = (9,)\n",
      "_lower = 1\n",
      "_upper = 2\n",
      "_lower = 1\n",
      "_upper = 3\n",
      "_lower = 2\n",
      "_upper = 4\n",
      "_lower = 3\n",
      "_upper = 4\n",
      "_lower = 1\n",
      "_upper = 2\n",
      "_lower = 1\n",
      "_upper = 3\n",
      "_lower = 2\n",
      "_upper = 4\n",
      "_lower = 3\n",
      "_upper = 4\n",
      "_lower = 1\n",
      "_upper = 2\n",
      "_lower = 1\n",
      "_upper = 3\n",
      "_lower = 2\n",
      "_upper = 4\n",
      "_lower = 3\n",
      "_upper = 4\n",
      "_lower = 1\n",
      "_upper = 2\n",
      "_lower = 1\n",
      "_upper = 3\n",
      "_lower = 2\n",
      "_upper = 4\n",
      "_lower = 3\n",
      "_upper = 4\n",
      "_lower = 1\n",
      "_upper = 2\n",
      "_lower = 1\n",
      "_upper = 3\n",
      "_lower = 2\n",
      "_upper = 4\n",
      "_lower = 3\n",
      "_upper = 4\n",
      "_lower = 1\n",
      "_upper = 2\n",
      "_lower = 1\n",
      "_upper = 3\n",
      "_lower = 2\n",
      "_upper = 4\n",
      "_lower = 3\n",
      "_upper = 4\n",
      "_lower = 1\n",
      "_upper = 2\n",
      "_lower = 1\n",
      "_upper = 3\n",
      "_lower = 2\n",
      "_upper = 4\n",
      "_lower = 3\n",
      "_upper = 4\n",
      "_lower = 1\n",
      "_upper = 2\n",
      "_lower = 1\n",
      "_upper = 3\n",
      "_lower = 2\n",
      "_upper = 4\n",
      "_lower = 3\n",
      "_upper = 4\n",
      "_lower = 1\n",
      "_upper = 2\n",
      "_lower = 1\n",
      "_upper = 3\n",
      "_lower = 2\n",
      "_upper = 4\n",
      "_lower = 3\n",
      "_upper = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3×4×1 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.5      0.25      0.3\n",
       " 0.2      0.166667  0.15\n",
       " 0.12069  0.1       0.1\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.166667   0.222222   0.0714286\n",
       " 0.0689655  0.136364   0.0408163\n",
       " 0.0405405  0.0449438  0.0283019\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0952381  0.111111  0.333333\n",
       " 0.0789474  0.117647  0.214286\n",
       " 0.137931   0.103448  0.097561\n",
       "\n",
       "[:, :, 4, 1] =\n",
       " 0.2       0.4       0.2\n",
       " 0.147059  0.25      0.1\n",
       " 0.1       0.153846  0.125"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(3,3,4,1))\n",
    "x = Param(x)\n",
    "x[:, :, 1, 1] = [1  2  3; 4  3  6; 7  8  9]\n",
    "x[:, :, 2, 1] = [1  2  1; 2  3  2; 3  4  3]\n",
    "x[:, :, 3, 1] = [2  1  2; 3  2  3; 4  3  4]\n",
    "x[:, :, 4, 1] = [4  2  1; 5  2  1; 2  2  4]\n",
    "y = LR_norm(x; k = 0, n = 2, alpha = 1, beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2×2×2 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       "  0.9419   0.828267\n",
       " -1.03967  0.209034\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " -0.62153   0.0951096\n",
       "  0.547716  0.00498526\n",
       "\n",
       "[:, :, 1, 2] =\n",
       " 0.0671877  -0.868887\n",
       " 2.07471     0.901451\n",
       "\n",
       "[:, :, 2, 2] =\n",
       "  0.0172826  0.980454\n",
       " -1.15379    0.0162631"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(2,2,2,2))\n",
    "x = Param(x)\n",
    "J = @diff sum(abs2, LR_norm(x))\n",
    "grad(J, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_LR_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function LR_norm(x::T; o...) where T\n",
    "    \n",
    "        nx, ny, nc, batch_size = size(x)\n",
    "        \n",
    "        x = mat(permutedims(x, (3,1,2,4)); dims = 1)\n",
    "\n",
    "        x = x'\n",
    "        \n",
    "        y = similar(x)\n",
    "    \n",
    "        x = getindex.([x], 1:size(x, 1), :)\n",
    "\n",
    "        y = _LR_norm.(x; o...)\n",
    "\n",
    "        y = vcat(y'...)\n",
    "\n",
    "        y = reshape(y, (nx, ny, batch_size, nc))\n",
    "\n",
    "        y = permutedims(y, (1,2,4,3))\n",
    "\n",
    "    return y\n",
    "end\n",
    "\n",
    "    function _LR_norm(x::T; k = 2, n = 5, alpha = 0.0001, beta = 0.75 , el_type = Float32) where T\n",
    "    \n",
    "    nc = length(x)\n",
    "    k, n, alpha, beta = convert.(el_type, [k, n, alpha, beta]) \n",
    "    \n",
    "    kernel_size = convert(Int, n+1)\n",
    "    l_padding = convert(Int, ceil(n/2))\n",
    "    r_padding = convert(Int, floor(n/2))\n",
    "    \n",
    "    x_ = reshape(vcat(zeros(el_type, l_padding), x, zeros(el_type, r_padding)), (nc + l_padding + r_padding, 1, 1, 1))\n",
    "    \n",
    "    w = reshape(ones(el_type, kernel_size), (kernel_size, 1, 1, 1))\n",
    "        \n",
    "    _sum = mat(conv4(w, x_.^2); dims = 4)\n",
    "\n",
    "    return x./((k .+ alpha .* _sum).^beta)\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3×4×1 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.5      0.25      0.3\n",
       " 0.2      0.166667  0.15\n",
       " 0.12069  0.1       0.1\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.166667   0.222222   0.0714286\n",
       " 0.0689655  0.136364   0.0408163\n",
       " 0.0405405  0.0449438  0.0283019\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0952381  0.111111  0.333333\n",
       " 0.0789474  0.117647  0.214286\n",
       " 0.137931   0.103448  0.097561\n",
       "\n",
       "[:, :, 4, 1] =\n",
       " 0.2       0.4       0.2\n",
       " 0.147059  0.25      0.1\n",
       " 0.1       0.153846  0.125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(3,3,4,1))\n",
    "x = Param(x)\n",
    "x[:, :, 1, 1] = [1  2  3; 4  3  6; 7  8  9]\n",
    "x[:, :, 2, 1] = [1  2  1; 2  3  2; 3  4  3]\n",
    "x[:, :, 3, 1] = [2  1  2; 3  2  3; 4  3  4]\n",
    "x[:, :, 4, 1] = [4  2  1; 5  2  1; 2  2  4]\n",
    "y = LR_norm(x; k = 0, n = 2, alpha = 1, beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2×2×2 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.161849   0.354331\n",
       " 0.817444  -0.277698\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.270671   0.0163726\n",
       " 0.221797  -0.804352\n",
       "\n",
       "[:, :, 1, 2] =\n",
       "  0.477411   0.486567\n",
       " -0.239793  -0.199782\n",
       "\n",
       "[:, :, 2, 2] =\n",
       "  0.651453  -0.376088\n",
       " -0.511495  -0.907096"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(2,2,2,2))\n",
    "x = Param(x)\n",
    "J = @diff sum(abs2, LR_norm(x))\n",
    "grad(J, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function LR_norm(x::T; k = 2, n = 5, alpha = 0.0001, beta = 0.75 , el_type = Float32) where T\n",
    "    \n",
    "        nx, ny, nc, batch_size = size(x)\n",
    "        k, n, alpha, beta = convert.(el_type, [k, n, alpha, beta]) \n",
    "\n",
    "        kernel_size = convert(Int, n+1)\n",
    "        l_padding = convert(Int, ceil(n/2))\n",
    "        r_padding = convert(Int, floor(n/2))\n",
    "\n",
    "        x_ = cat(zeros((nx,ny,l_padding,batch_size)), x, dims = 3)\n",
    "        x_ = cat(x_, zeros((nx,ny,r_padding,batch_size)), dims = 3)\n",
    "        \n",
    "        #w = reshape(ones(el_type, (nc + l_padding + r_padding) * nc ), (nc + l_padding + r_padding, 1, , nc))\n",
    "\n",
    "        w = reshape(ones(el_type, nx * ny * kernel_size), (kernel_size, 1, ny, nx))\n",
    "        #w = reshape(ones(el_type, nx * 1 * kernel_size), (kernel_size, 1, 1, nx))\n",
    "        \n",
    "        x_ = permutedims(x_, (3,1,2,4))\n",
    "        #_sum = depthwiseconv(x_.^2, w)\n",
    "        _sum = conv4(w, x_.^2)\n",
    "     \n",
    "        _sum = permutedims(_sum, (3,2,1,4))\n",
    "\n",
    "    return x./((k .+ alpha .* _sum).^beta)\n",
    "         \n",
    "\n",
    "      \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3×4×1 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.05  0.025641   0.0131579\n",
       " 0.2   0.0384615  0.0263158\n",
       " 0.35  0.102564   0.0394737\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0344828  0.02  0.00371747\n",
       " 0.0689655  0.03  0.00743494\n",
       " 0.103448   0.04  0.0111524\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.0555556  0.0144928  0.020202\n",
       " 0.0833333  0.0289855  0.030303\n",
       " 0.111111   0.0434783  0.040404\n",
       "\n",
       "[:, :, 4, 1] =\n",
       " 0.133333   0.0384615  0.0153846\n",
       " 0.166667   0.0384615  0.0153846\n",
       " 0.0666667  0.0384615  0.0615385"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(3,3,4,1))\n",
    "x = Param(x)\n",
    "x[:, :, 1, 1] = [1  2  3; 4  3  6; 7  8  9]\n",
    "x[:, :, 2, 1] = [1  2  1; 2  3  2; 3  4  3]\n",
    "x[:, :, 3, 1] = [2  1  2; 3  2  3; 4  3  4]\n",
    "x[:, :, 4, 1] = [4  2  1; 5  2  1; 2  2  4]\n",
    "y = LR_norm(x; k = 0, n = 2, alpha = 1, beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Slow fallback implementation invoked for ∇conv_data!  You probably don't want this; check your datatypes.\n",
      "│   yT = Float64\n",
      "│   T1 = Float64\n",
      "│   T2 = Float32\n",
      "└ @ NNlib C:\\Users\\volkan\\.julia\\packages\\NNlib\\2Wxlq\\src\\conv.jl:206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2×2×2 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.115215  0.109449\n",
       " 0.359937  0.608754\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " -0.666619    -0.183724\n",
       " -0.00813191   0.309822\n",
       "\n",
       "[:, :, 1, 2] =\n",
       " -0.228018  0.596748\n",
       " -0.770403  0.139626\n",
       "\n",
       "[:, :, 2, 2] =\n",
       " 1.18588   -0.338958\n",
       " 0.450504   1.18308"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(2,2,2,2))\n",
    "x = Param(x)\n",
    "J = @diff sum(abs2, LR_norm(x))\n",
    "grad(J, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function LR_norm(x::T; k = 2, n = 5, alpha = 0.0001, beta = 0.75 , el_type = Float32) where T\n",
    "            k, alpha, beta = convert.(el_type, [k, alpha, beta]) \n",
    "\n",
    "           nx, ny, nc, batch_size = size(x)\n",
    "           x = permutedims(x, (3,1,2,4))\n",
    "           x = reshape(x, (nc, nx * ny, 1, batch_size))\n",
    "           kernel_size = convert(Int, n+1)\n",
    "           #l_padding = convert(Int, ceil(n/2))\n",
    "           #r_padding = convert(Int, floor(n/2))\n",
    "           w = reshape(ones(el_type, kernel_size), (kernel_size, 1, 1, 1))\n",
    "\n",
    "           _sum = conv4(w, x.^2; padding=(convert(Int, ceil(n/2)), 0))\n",
    "            @show _sum\n",
    "           println(size(_sum))\n",
    "            println(divrem(n, 2)[2])\n",
    "    _sum = _sum[1:(end - divrem(n, 2)[2]), :, :, :]\n",
    "    \n",
    "    println(size(_sum))\n",
    "\n",
    "           y = x./((k .+ alpha .* _sum).^beta)\n",
    "           println(size(y))\n",
    "           y = reshape(y, (nc, nx, ny, batch_size))\n",
    "           y = permutedims(y, (2,3,1,4))\n",
    "           return y\n",
    " end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sum = Float32[6.0 29.0 74.0 9.0 22.0 89.0 14.0 49.0 106.0; 22.0 54.0 78.0 13.0 26.0 93.0 15.0 50.0 122.0; 22.016237 54.00505 79.347855 13.336161 26.02192 93.02641 15.288069 52.83959 122.20041; 22.229982 55.000565 79.36575 13.475053 26.16474 93.65268 15.862909 52.95526 124.34024; 22.178411 39.807907 30.392681 9.833733 17.537857 29.675438 9.737771 17.439756 44.318428; 22.12865 37.43903 21.443958 6.0154915 8.655146 14.096523 8.756595 13.572687 37.579597; 18.702986 28.450703 5.745508 5.716008 6.463887 5.152652 5.743382 7.4537773 22.153341; 2.717424 3.4509714 1.7613361 1.9070263 3.1714578 3.3805761 8.9846115 6.5367146 6.204432; 2.9233763 4.6582108 0.47381315 3.9295945 6.2745457 3.3575506 8.987156 6.043023 6.0976963; 3.480628 3.6626978 0.567831 3.81488 8.644521 4.544375 9.20323 5.935962 4.0187163; 2.5321999 2.8553524 0.5409064 3.4562006 8.271402 4.521616 6.3283687 5.4514685 3.0405247; 1.5819603 1.2242312 0.48962772 3.2744417 8.154115 4.10053 6.3095446 5.318537 0.77935547; 1.0076264 1.212559 0.18807925 2.5739245 6.345373 4.044401 5.3227572 2.437447 0.20561332]\n",
      "(13, 9, 1, 1)\n",
      "1\n",
      "(12, 9, 1, 1)\n",
      "(12, 9, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3×12×1 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 0.166667   0.222222   0.214286\n",
       " 0.137931   0.136364   0.122449\n",
       " 0.0945946  0.0898876  0.0849057\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.0454545  0.153846   0.0666667\n",
       " 0.037037   0.115385   0.04\n",
       " 0.0384615  0.0430108  0.0245902\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 0.090842   0.0749841  0.130821\n",
       " 0.0555504  0.0768583  0.0567756\n",
       " 0.0504109  0.0322489  0.0327331\n",
       "\n",
       "...\n",
       "\n",
       "[:, :, 10, 1] =\n",
       " 0.0345232  -0.114566  0.223772\n",
       " 0.0044788   0.097307  0.0485159\n",
       " 0.221562    0.328455  0.0562451\n",
       "\n",
       "[:, :, 11, 1] =\n",
       " -0.18615   -0.444365   -0.0851854\n",
       "  0.385606  -0.213721    0.280958\n",
       " -0.454116  -0.0128778   0.100662\n",
       "\n",
       "[:, :, 12, 1] =\n",
       "  0.555048    -0.0474866   0.140951\n",
       " -0.00091907  -0.194402   -0.0174512\n",
       "  0.683248     0.328374    0.316506"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(3,3,12,1))\n",
    "#x = Param(x)\n",
    "x[:, :, 1, 1] = [1  2  3; 4  3  6; 7  8  9]\n",
    "x[:, :, 2, 1] = [1  2  1; 2  3  2; 3  4  3]\n",
    "x[:, :, 3, 1] = [2  1  2; 3  2  3; 4  3  4]\n",
    "x[:, :, 4, 1] = [4  2  1; 5  2  1; 2  2  4]\n",
    "y1 = LR_norm(x; k = 0, n = 5, alpha = 1, beta = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_sum = R(Array{Float32,4}(3,4,1,2))\n",
      "(3, 4, 1, 2)\n",
      "1\n",
      "(2, 4, 1, 2)\n",
      "(2, 4, 1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2×2×2 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       "  0.338469  -1.71724\n",
       " -0.771704  -1.3464\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 0.407922  0.135006\n",
       " 0.501176  0.904699\n",
       "\n",
       "[:, :, 1, 2] =\n",
       " -1.21041   -0.0561789\n",
       "  0.260603   0.209304\n",
       "\n",
       "[:, :, 2, 2] =\n",
       " -0.713168  1.06001\n",
       "  0.770997  0.403031"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Array{Float32}(randn(2,2,2,2))\n",
    "x = Param(x)\n",
    "J = @diff sum(abs2, LR_norm(x; n = 5))\n",
    "grad(J, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "using Test\n",
    "a = randn(50,300,120,10)\n",
    "aa = permutedims(a, (3,1,2,4))\n",
    "aaa = mat(aa; dims = 1)\n",
    "aaa = permutedims(aaa, (2,1))\n",
    "aaaa = reshape(aaa, (50,300,10,120))\n",
    "aaaaa = permutedims(aaaa, (1,2,4,3))\n",
    "@test aaaaa == a\n",
    "=#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
